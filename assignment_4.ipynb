{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+git://github.com/andreinechaev/nvcc4jupyter.git\n",
      "  Cloning git://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-u4dddw76\n",
      "Requirement already satisfied (use --upgrade to upgrade): NVCCPlugin==0.0.2 from git+git://github.com/andreinechaev/nvcc4jupyter.git in /home/nineleaps/anaconda3/lib/python3.7/site-packages\n",
      "Building wheels for collected packages: NVCCPlugin\n",
      "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /tmp/pip-ephem-wheel-cache-_2bm1wpi/wheels/10/c2/05/ca241da37bff77d60d31a9174f988109c61ba989e4d4650516\n",
      "Successfully built NVCCPlugin\n",
      "directory /home/nineleaps/Desktop/src already exists\n",
      "Out bin /home/nineleaps/Desktop/result.out\n"
     ]
    }
   ],
   "source": [
    "!pip install git+git://github.com/andreinechaev/nvcc4jupyter.git\n",
    "%load_ext nvcc_plugin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cu\n",
    "#include<stdio.h>\n",
    "__managed__ int sum=0;\n",
    "__global__ void Array_sum(int *a,int *n)\n",
    "{\n",
    "    int tid=threadIdx.x;\n",
    "    if(tid<*n)\n",
    "      atomicAdd(&sum,a[tid]);\n",
    "}\n",
    "\n",
    "int main()\n",
    "{\n",
    "    int n=10,i;\n",
    "    //printf(\"Enter N:\");\n",
    "    //scanf(\"%d\",&n);\n",
    "    int a[n];\n",
    "    int *cuda_a,*cuda_n;\n",
    " \n",
    "    for(i=0;i<n;i++)\n",
    "    {\n",
    "        a[i]=rand()%100;\n",
    "        printf(\"%d \",a[i]);\n",
    "    }\n",
    "    printf(\"\\n\");\n",
    "\n",
    "    cudaMalloc((void**)&cuda_a,n*sizeof(int));\n",
    "    cudaMalloc((void**)&cuda_n,sizeof(int));\n",
    "    \n",
    "    cudaMemcpy(cuda_a,a,n*sizeof(int),cudaMemcpyHostToDevice);\n",
    "    cudaMemcpy(cuda_n,&n,sizeof(int),cudaMemcpyHostToDevice);\n",
    "    Array_sum <<<1,n>>>(cuda_a,cuda_n);\n",
    "    printf(\"Sum:%d\\n\",sum);\n",
    "    cudaFree(cuda_a);\n",
    "    cudaFree(cuda_n);\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8 6 7 1 9 3 8 9 4 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sum:56"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cu\n",
    "#include<stdio.h>\n",
    "\n",
    "__global__ void Array_add(int *a,int *b,int *c,int *n)\n",
    "{\n",
    "    unsigned short tid=threadIdx.x;\n",
    "    if(tid<*n)\n",
    "      c[tid]=a[tid]+b[tid];\n",
    "}\n",
    "\n",
    "int main()\n",
    "{\n",
    "    int n=5,i;\n",
    "    //printf(\"Enter N:\");\n",
    "    //scanf(\"%d\",&n);\n",
    "    int a[n],b[n],c[n];\n",
    "    int *cuda_a,*cuda_b,*cuda_c,*cuda_n;\n",
    " \n",
    "    for(i=0;i<n;i++)\n",
    "      a[i]=rand()%100;\n",
    "    for(i=0;i<n;i++)\n",
    "      b[i]=rand()%100;\n",
    "\n",
    "    cudaMalloc((void**)&cuda_a,n*sizeof(int));\n",
    "    cudaMalloc((void**)&cuda_b,n*sizeof(int));\n",
    "    cudaMalloc((void**)&cuda_c,n*sizeof(int));\n",
    "    cudaMalloc((void**)&cuda_n,sizeof(int));\n",
    "    \n",
    "    cudaMemcpy(cuda_a,a,n*sizeof(int),cudaMemcpyHostToDevice);\n",
    "    cudaMemcpy(cuda_b,b,n*sizeof(int),cudaMemcpyHostToDevice);\n",
    "    cudaMemcpy(cuda_n,&n,sizeof(int),cudaMemcpyHostToDevice);\n",
    "    Array_add <<<1,n>>>(cuda_a,cuda_b,cuda_c,cuda_n);\n",
    "    cudaMemcpy(c,cuda_c,n*sizeof(int),cudaMemcpyDeviceToHost);\n",
    "    for(i=0;i<n;i++)\n",
    "      printf(\"%d + %d = %d\\n\",a[i],b[i],c[i]);\n",
    "    cudaFree(cuda_a);\n",
    "    cudaFree(cuda_b);\n",
    "    cudaFree(cuda_c);\n",
    "    cudaFree(cuda_n);\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8 + 3 = 11 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8 + 6 = 14 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7 + 2 = 9 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 + 4 = 5 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9 + 1 = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cu\n",
    "#include<stdio.h>\n",
    "\n",
    "__global__ void Matrix_mult(int *a,int *b,int *c,int *m,int *n,int *p)\n",
    "{\n",
    "    int col=blockIdx.y*blockDim.y+threadIdx.y;\n",
    "    int row=blockIdx.x*blockDim.x+threadIdx.x;\n",
    "    int temp=0,i;\n",
    "\n",
    "    if(row<*m&&col<*p)\n",
    "    for(i=0;i<*n;i++)\n",
    "      temp+=a[row*(*n)+i]*b[i*(*p)+col];\n",
    "    c[row*(*p)+col]=temp;\n",
    "}\n",
    "\n",
    "int main()\n",
    "{\n",
    "    int m=3,n=2,p=2,i,j;\n",
    "    //printf(\"Enter N:\");\n",
    "    //scanf(\"%d\",&n);\n",
    "    int a[m*n],b[n*p],c[m*n];\n",
    "    int *cuda_a,*cuda_b,*cuda_c,*cuda_m,*cuda_n,*cuda_p;\n",
    "    printf(\"Matrix A:\\n\");\n",
    "    for(i=0;i<m;i++)\n",
    "    {\n",
    "        for(j=0;j<n;j++)\n",
    "        {\n",
    "            a[i*n+j]=rand()%100;\n",
    "            printf(\"%d \",a[i*n+j]);       \n",
    "        }\n",
    "        printf(\"\\n\");\n",
    "    }\n",
    "    printf(\"\\nMatrix B:\\n\");\n",
    "    for(i=0;i<n;i++)\n",
    "    {\n",
    "        for(j=0;j<p;j++)\n",
    "        {\n",
    "            b[i*p+j]=rand()%100;\n",
    "            printf(\"%d \",b[i*p+j]);       \n",
    "        }\n",
    "        printf(\"\\n\");\n",
    "    }\n",
    "    printf(\"\\n\");\n",
    "\n",
    "    cudaMalloc((void**)&cuda_a,m*n*sizeof(int));\n",
    "    cudaMalloc((void**)&cuda_b,n*p*sizeof(int));\n",
    "    cudaMalloc((void**)&cuda_c,m*p*sizeof(int));\n",
    "    cudaMalloc((void**)&cuda_m,sizeof(int));\n",
    "    cudaMalloc((void**)&cuda_n,sizeof(int));\n",
    "    cudaMalloc((void**)&cuda_p,sizeof(int));\n",
    "\n",
    "    cudaMemcpy(cuda_a,a,m*n*sizeof(int),cudaMemcpyHostToDevice);\n",
    "    cudaMemcpy(cuda_b,b,n*p*sizeof(int),cudaMemcpyHostToDevice);\n",
    "    cudaMemcpy(cuda_m,&m,sizeof(int),cudaMemcpyHostToDevice);\n",
    "    cudaMemcpy(cuda_n,&n,sizeof(int),cudaMemcpyHostToDevice);\n",
    "    cudaMemcpy(cuda_p,&p,sizeof(int),cudaMemcpyHostToDevice);\n",
    " \n",
    "    dim3 threadsPerBlock(m,p);\n",
    "    dim3 blocksPerGrid(1,1);\n",
    "        \n",
    "\n",
    "    Matrix_mult<<<blocksPerGrid,threadsPerBlock>>> (cuda_a,cuda_b,cuda_c,cuda_m,cuda_n,cuda_p);   \n",
    "\n",
    "    cudaMemcpy(c,cuda_c,m*p*sizeof(int),cudaMemcpyDeviceToHost);\n",
    "    printf(\"Result Matrix:\\n\");\n",
    "    for(i=0;i<m;i++)\n",
    "    {\n",
    "        for(j=0;j<p;j++)\n",
    "        {\n",
    "            printf(\"%d \",c[i*p+j]);       \n",
    "        }\n",
    "        printf(\"\\n\");\n",
    "    }\n",
    "    cudaFree(cuda_a);\n",
    "    cudaFree(cuda_b);\n",
    "    cudaFree(cuda_c);\n",
    "    cudaFree(cuda_m);\n",
    "    cudaFree(cuda_n);\n",
    "    cudaFree(cuda_p);\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrix A:\n",
    "\n",
    "1 2\n",
    "\n",
    "3 4\n",
    "\n",
    "Matrix B :\n",
    "\n",
    "1 1\n",
    "\n",
    "1 1\n",
    "\n",
    "Result matrix\n",
    "\n",
    "3 3\n",
    "\n",
    "7 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cu\n",
    "#include<thrust/host_vector.h>\n",
    "#include<thrust/device_vector.h>\n",
    "#include<thrust/generate.h>\n",
    "#include<thrust/sort.h>\n",
    "#include<thrust/copy.h>\n",
    "#include<cstdlib>\n",
    "\n",
    "int main()\n",
    "{\n",
    "    thrust::host_vector<int> a(10);\n",
    "    thrust::generate(a.begin(),a.end(),rand);\n",
    "    thrust::device_vector<int> device_a=a;\n",
    "    thrust::sort(device_a.begin(),device_a.end());\n",
    "    thrust::copy(device_a.begin(),device_a.end(),a.begin());\n",
    "    for(auto x:a)\n",
    "      printf(\"%d \",x);\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "424 596 719 846 118 164 168 171 180 195"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
